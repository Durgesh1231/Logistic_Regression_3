{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9B_EK4Me9ix"
      },
      "outputs": [],
      "source": [
        "# Q1: Concept of precision and recall in classification models\n",
        "\n",
        "# Precision:\n",
        "# - The ratio of true positive predictions to the total positive predictions.\n",
        "# - Indicates how many predicted positives are actually correct.\n",
        "# Formula: Precision = TP / (TP + FP)\n",
        "\n",
        "# Recall:\n",
        "# - The ratio of true positive predictions to the total actual positives.\n",
        "# - Indicates how many actual positives are correctly predicted.\n",
        "# Formula: Recall = TP / (TP + FN)\n",
        "\n",
        "# Example in Python:\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # For multiclass, use 'weighted' or 'macro'\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Q2: F1 Score and its calculation\n",
        "\n",
        "# F1 Score:\n",
        "# - The harmonic mean of precision and recall.\n",
        "# - Useful for imbalanced datasets.\n",
        "# Formula: F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "# Difference:\n",
        "# - Precision focuses on false positives, recall focuses on false negatives.\n",
        "# - F1 Score balances both metrics.\n",
        "\n",
        "# Example in Python:\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Q3: ROC and AUC\n",
        "\n",
        "# ROC (Receiver Operating Characteristic) Curve:\n",
        "# - Plots True Positive Rate (TPR) vs. False Positive Rate (FPR) for different thresholds.\n",
        "\n",
        "# AUC (Area Under the Curve):\n",
        "# - Measures the area under the ROC curve.\n",
        "# - A higher AUC indicates better model performance.\n",
        "\n",
        "# Example in Python:\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # For binary classification\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.plot(fpr, tpr, label='ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "print(\"AUC:\", auc)\n",
        "\n",
        "# Q4: Choosing the best metric\n",
        "\n",
        "# - Use Precision, Recall, or F1 Score for imbalanced datasets.\n",
        "# - Use Accuracy for balanced datasets.\n",
        "# - Use AUC-ROC for evaluating probabilistic models.\n",
        "\n",
        "# Multiclass classification vs. binary classification:\n",
        "# - Binary: Two classes (e.g., Yes/No).\n",
        "# - Multiclass: More than two classes (e.g., Cat/Dog/Bird).\n",
        "\n",
        "# Q5: Logistic regression for multiclass classification\n",
        "\n",
        "# - Logistic regression uses the \"one-vs-rest\" (OvR) or \"softmax\" (multinomial) approach for multiclass classification.\n",
        "\n",
        "# Example in Python:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Q6: Steps for an end-to-end multiclass classification project\n",
        "\n",
        "# 1. Define the problem and gather data.\n",
        "# 2. Perform data preprocessing (e.g., encoding, scaling).\n",
        "# 3. Split data into training, validation, and testing sets.\n",
        "# 4. Choose a classification algorithm (e.g., Logistic Regression, Random Forest).\n",
        "# 5. Train the model and tune hyperparameters.\n",
        "# 6. Evaluate the model using metrics like Precision, Recall, F1 Score.\n",
        "# 7. Deploy the model and monitor its performance.\n",
        "\n",
        "# Q7: What is model deployment and why is it important?\n",
        "\n",
        "# - Model deployment makes the trained model accessible to end-users or applications.\n",
        "# - Enables real-time or batch predictions in production environments.\n",
        "\n",
        "# Q8: Multi-cloud platforms for model deployment\n",
        "\n",
        "# - Multi-cloud platforms use multiple cloud providers (e.g., AWS, Azure, GCP) for deployment.\n",
        "# - Allow flexibility and reduce dependency on a single provider.\n",
        "\n",
        "# Q9: Benefits and challenges of multi-cloud deployment\n",
        "\n",
        "# Benefits:\n",
        "# - Redundancy and reliability.\n",
        "# - Cost optimization by leveraging multiple providers.\n",
        "# - Avoid vendor lock-in.\n",
        "\n",
        "# Challenges:\n",
        "# - Increased complexity in managing deployments.\n",
        "# - Security and compliance across platforms.\n",
        "# - Performance variability between providers.\n",
        "\n",
        "# Example of deploying a model using Flask (single-cloud or multi-cloud compatible):\n",
        "from flask import Flask, request, jsonify\n",
        "import pickle\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = pickle.load(open(\"multiclass_model.pkl\", \"rb\"))\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.json\n",
        "    prediction = model.predict([data['features']])\n",
        "    return jsonify({'class': prediction[0]})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    }
  ]
}